{"cells":[{"cell_type":"markdown","metadata":{"id":"qrEJ2CzkJ4_W"},"source":["# 1 导入库"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4256,"status":"ok","timestamp":1655648822450,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"},"user_tz":-480},"id":"IATg8ZkqJ4_X","outputId":"60c343dc-fe1b-4614-d547-72253e28a990"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import pandas as pd \n","import numpy as np \n","from nltk import word_tokenize \n","import nltk\n","nltk.download('punkt')\n","from keras.callbacks import Callback\n","from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n","\n","from tensorflow.keras.layers import Dense,Input,Dropout,Embedding,LSTM,Bidirectional\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","\n","from sklearn.model_selection import train_test_split\n","\n","import json\n","\n","import time # 记录模型训练时间\n"]},{"cell_type":"markdown","metadata":{"id":"LU2eJ6qBJ4_a"},"source":["# 2 设置神经网络参数\n","\n","为了方便统一设置，我们在这里指定神经网络训练时所需要的参数，在后面的代码中可以直接引用。"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"X4Xm4AF9J4_b","executionInfo":{"status":"ok","timestamp":1655649145999,"user_tz":-480,"elapsed":9,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["# 批次大小\n","batch_size = 128\n","\n","# 训练周期\n","epochs = 3\n","\n","# 词向量长度\n","embedding_dims = 128\n","\n","# cell数量\n","lstm_cell = 64"]},{"cell_type":"markdown","metadata":{"id":"XHNlgrcPJ4_c"},"source":["# 3 数据加载\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":107117,"status":"ok","timestamp":1655648929555,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"},"user_tz":-480},"id":"Q2GOOCk7Q20y","outputId":"71448d46-fc5c-4e70-e5e8-edf9404c688e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"XTzO4bhXQ-cx","executionInfo":{"status":"ok","timestamp":1655648929558,"user_tz":-480,"elapsed":37,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["import os\n","#os.chdir(\"/content/drive/Shared drives/项目名\")\n","os.chdir(\"/content/gdrive/MyDrive/ai_lab_final\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"lNstJYZXJ4_e","executionInfo":{"status":"ok","timestamp":1655648932127,"user_tz":-480,"elapsed":2597,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["data = pd.read_csv('train.csv')"]},{"cell_type":"markdown","metadata":{"id":"1hmo-bTLQHX6"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"qKfgFKduJ4_f"},"source":["## 3.1 统计样本数量"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1655648932128,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"},"user_tz":-480},"id":"hFvpM9iYJ4_g","outputId":"9fa1ce5b-0459-4f05-c1d7-e50f19dfcab1"},"outputs":[{"output_type":"stream","name":"stdout","text":["样本总数：13000\n","正样本数量： 1454\n","负样本数量： 11546\n"]}],"source":["print('样本总数：%d' % data.shape[0])\n","\n","# 计算正样本数量\n","poslen = sum(data['gold_label']==1)\n","\n","# 计算负样本数量\n","neglen = sum(data['gold_label']==0)\n","print('正样本数量：', poslen)\n","print('负样本数量：', neglen)"]},{"cell_type":"markdown","metadata":{"id":"K_ZEonGXJ4_h"},"source":["# 4 文本分词"]},{"cell_type":"markdown","metadata":{"id":"wI1eg3EPyAKf"},"source":["## 4.1 调用nltk包中的分词函数"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"-vVeEqY5J4_j","executionInfo":{"status":"ok","timestamp":1655648934547,"user_tz":-480,"elapsed":2425,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["#定义分词函数，对传入的x进行分词\n","cw = lambda x: list(word_tokenize(x))\n","\n","# apply传入一个函数，把cw函数应用到data['sentence']的每一行\n","# 把分词后的结果保存到data['words']中\n","data['words'] = data['sentence'].apply(cw)"]},{"cell_type":"markdown","metadata":{"id":"FvNVuzB8J4_k"},"source":["# 5 文本数据预处理"]},{"cell_type":"markdown","metadata":{"id":"PP0XrJUryDT9"},"source":["\n","## 5.1 统计词汇最大长度"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"CPlMUh2ZJ4_m","executionInfo":{"status":"ok","timestamp":1655648934550,"user_tz":-480,"elapsed":48,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["max_length = max([len(x) for x in data['words']])"]},{"cell_type":"markdown","metadata":{"id":"WKVIhIjKJ4_m"},"source":["## 5.2 数据格式转换\n","\n","把 `data['words']`  中所有的 `list` 都变成字符串格式："]},{"cell_type":"code","execution_count":9,"metadata":{"id":"SERd-6pgJ4_n","executionInfo":{"status":"ok","timestamp":1655648934551,"user_tz":-480,"elapsed":41,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["texts = [' '.join(x) for x in data['words']]"]},{"cell_type":"markdown","metadata":{"id":"vAcS4bDkJ4_n"},"source":["## 5.3 `Tokenizer` 获取词向量"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"2ikicLOWJ4_o","executionInfo":{"status":"ok","timestamp":1655648936574,"user_tz":-480,"elapsed":2054,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["# 实例化Tokenizer，设置字典中最大词汇数为30000\n","# Tokenizer会自动过滤掉一些符号比如：!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\n","tokenizer = Tokenizer(num_words=30000)\n","\n","# 传入我们的训练数据，建立词典，词的编号根据词频设定，频率越大，编号越小，\n","tokenizer.fit_on_texts(texts) \n","\n","# 把词转换为编号，编号大于30000的词会被过滤掉\n","sequences = tokenizer.texts_to_sequences(texts) "]},{"cell_type":"markdown","metadata":{"id":"GQdEsSPSJ4_o"},"source":["## 5.4 序列填充\n","\n","- 把序列设定为 `max_length` 的长度，超过 `max_length` 的部分舍弃，不到 `max_length` 则补 `0`\n","- `padding='pre'` 在句子前面进行填充，`padding='post'` 在句子后面进行填充，本实验选择句前填充"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"KfXWt5q2J4_p","executionInfo":{"status":"ok","timestamp":1655648936576,"user_tz":-480,"elapsed":47,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["X = pad_sequences(sequences, maxlen=max_length, padding='pre')"]},{"cell_type":"markdown","metadata":{"id":"sIos2kfiJ4_q"},"source":["## 5.5 保存 Tokenizer\n","\n","将 `tokenizer` 保存为 json 文件："]},{"cell_type":"code","execution_count":12,"metadata":{"id":"5gw1qvZLJ4_r","executionInfo":{"status":"ok","timestamp":1655648936578,"user_tz":-480,"elapsed":40,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["# 把token_config保存到json文件中，模型预测阶段可以使用\n","file = open('./model/token_config_lstm.json', 'w', encoding = \"ISO-8859-1\")\n","\n","# 把tokenizer变成json数据\n","token_config = tokenizer.to_json()\n","\n","# 保存json数据\n","json.dump(token_config, file)"]},{"cell_type":"markdown","metadata":{"id":"3rBNZY3KJ4_r"},"source":["## 5.6 定义标签\n","\n","将标签定义为独热编码，其中 `01` 为正样本 (积极)，`10` 为负样本 (消极)："]},{"cell_type":"code","execution_count":13,"metadata":{"id":"lxKTeoy-J4_r","executionInfo":{"status":"ok","timestamp":1655648936581,"user_tz":-480,"elapsed":41,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["positive_labels = [[0, 1] for _ in range(poslen)]\n","negative_labels = [[1, 0] for _ in range(neglen)]"]},{"cell_type":"markdown","metadata":{"id":"GhjHnEsSJ4_s"},"source":["## 5.7 合并标签\n","\n","将正样本 (积极) 标签和负样本 (消极) 标签进行合并用于训练模型："]},{"cell_type":"code","execution_count":14,"metadata":{"id":"TM8TMoo_J4_s","executionInfo":{"status":"ok","timestamp":1655648936583,"user_tz":-480,"elapsed":41,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["Y = np.array(positive_labels + negative_labels)"]},{"cell_type":"markdown","metadata":{"id":"oZAchsaUJ4_t"},"source":["## 5.8 切分数据\n","\n","调用 `train_test_split` 对数据进行切分，其中测试集占 `0.2`，即训练集与测试集比例为 8:2"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"kK-aMp0vJ4_t","executionInfo":{"status":"ok","timestamp":1655648936584,"user_tz":-480,"elapsed":39,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.2)"]},{"cell_type":"markdown","metadata":{"id":"TTaidUcEJ4_u"},"source":["# 6 模型定义"]},{"cell_type":"markdown","metadata":{"id":"_XzMPHQNCRaT"},"source":["## 自定义f1score计算"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"rlDR1ZDCdq5W","executionInfo":{"status":"ok","timestamp":1655648936586,"user_tz":-480,"elapsed":39,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["class Metrics(Callback):\n","  def __init__(self, val_data, val_label):\n","      super(Callback, self).__init__()\n","      self.val_data = val_data\n","      self.val_label = val_label\n","  def on_train_begin(self, logs={}):\n","    self.val_f1s = []\n","  def on_epoch_end(self, epoch, logs={}):\n","    val_predict=(np.asarray(self.model.predict(self.val_data))).round()\n","    val_targ = self.val_label\n","    _val_f1 = f1_score(val_targ, val_predict, average='micro')\n","    self.val_f1s.append(_val_f1)\n","    print(\"— val_f1: %f \" % _val_f1)\n","    return"]},{"cell_type":"markdown","metadata":{"id":"vmhIrbv0TuTE"},"source":["## 自定义学习率"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"1FHzhQhuTnwQ","executionInfo":{"status":"ok","timestamp":1655648936587,"user_tz":-480,"elapsed":37,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["import keras.backend as K\n","from keras.callbacks import LearningRateScheduler\n"," \n","def scheduler(epoch):\n","    # 每隔1个epoch，学习率减小为原来的1/2\n","    if epoch % 3 == 0 and epoch != 0:\n","        lr = K.get_value(model.optimizer.lr)\n","        K.set_value(model.optimizer.lr, lr * 0.5)\n","        print(\"lr changed to {}\".format(lr * 0.5))\n","    return K.get_value(model.optimizer.lr)"]},{"cell_type":"markdown","metadata":{"id":"4qsP5ELNUcGr"},"source":["## 模型定义"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"uh3_pSZnJ4_v","executionInfo":{"status":"ok","timestamp":1655648937564,"user_tz":-480,"elapsed":1012,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["# 定义模型输入，shape-(batch, 202)\n","sequence_input = Input(shape=(max_length,))\n","\n","# Embedding层，30000表示30000个词，每个词对应的向量为128维\n","embedding_layer = Embedding(input_dim=30000, output_dim=embedding_dims)\n","\n","# embedded_sequences的shape-(batch, 202, 128)\n","embedded_sequences = embedding_layer(sequence_input)\n","\n","# 双向LSTM\n","x = Bidirectional(LSTM(lstm_cell))(embedded_sequences)\n","\n","# 全连接层\n","x = Dense(128, activation='relu')(x)\n","\n","# Dropout层\n","x = Dropout(0.5)(x)\n","\n","# 输出层\n","preds = Dense(2, activation='softmax')(x)\n","\n","# 定义模型\n","model = Model(sequence_input, preds)"]},{"cell_type":"markdown","metadata":{"id":"DYCoOQqFJ4_w"},"source":["神经网络模型架构如下所示：\n","\n","![Alt text](./img/lstm_model.h5.svg)"]},{"cell_type":"markdown","metadata":{"id":"whzMfYnhJ4_w"},"source":["## 模型编译"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"-OUXurVNJ4_w","executionInfo":{"status":"ok","timestamp":1655648937566,"user_tz":-480,"elapsed":38,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["#自定义学习率\n","reduce_lr = LearningRateScheduler(scheduler)\n","# 自定义f1 score\n","metrics = Metrics(x_test, y_test)\n","# 定义代价函数，优化器\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['acc'])"]},{"cell_type":"markdown","metadata":{"id":"TMl8kzEZJ4_x"},"source":["## 模型训练"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LL8UHHpYJ4_x","executionInfo":{"status":"ok","timestamp":1655649775153,"user_tz":-480,"elapsed":622122,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}},"outputId":"b6b86b81-333a-4ca6-de85-f9984d025a3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","82/82 [==============================] - ETA: 0s - loss: 0.3612 - acc: 0.8868— val_f1: 0.893462 \n","82/82 [==============================] - 191s 2s/step - loss: 0.3612 - acc: 0.8868 - val_loss: 0.3406 - val_acc: 0.8935 - lr: 0.0010\n","Epoch 2/3\n","82/82 [==============================] - ETA: 0s - loss: 0.3081 - acc: 0.8892— val_f1: 0.890385 \n","82/82 [==============================] - 190s 2s/step - loss: 0.3081 - acc: 0.8892 - val_loss: 0.3985 - val_acc: 0.8904 - lr: 0.0010\n","Epoch 3/3\n","82/82 [==============================] - ETA: 0s - loss: 0.1502 - acc: 0.9477— val_f1: 0.799615 \n","82/82 [==============================] - 189s 2s/step - loss: 0.1502 - acc: 0.9477 - val_loss: 0.5272 - val_acc: 0.7996 - lr: 0.0010\n","训练耗时： 621.9807171821594 秒\n"]}],"source":["start = time.time() # 记录训练开始时间\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          callbacks=[metrics, reduce_lr],\n","          validation_data=(x_test, y_test))\n","end = time.time() # 记录训练结束时间\n","print('训练耗时：',end - start, '秒')"]},{"cell_type":"markdown","metadata":{"id":"3guTgt3KJ4_y"},"source":["## 模型保存\n","\n","训练完一个模型后，为了以后重复使用，需要对模型的结果进行保存。用 Tensorflow 去实现神经网络，所要保存的就是神经网络中的各项权重值。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5NJ-9PtVJ4_y","executionInfo":{"status":"aborted","timestamp":1655649004608,"user_tz":-480,"elapsed":235,"user":{"displayName":"Li Wa Tang","userId":"14219100965086985702"}}},"outputs":[],"source":["model.save('./model/lstm_model.h5')"]}],"metadata":{"anaconda-cloud":{},"colab":{"collapsed_sections":[],"name":"bi_lstm_training_v4.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":0}